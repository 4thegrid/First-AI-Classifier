# -*- coding: utf-8 -*-
"""CoverType-classification.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11250dRuo0csyd0dtnQ9OUZKSla7wRfGE
"""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from google.colab import drive
from tensorflow.keras.models import Sequential
from sklearn.compose import ColumnTransformer
from tensorflow.keras.layers import Dense
from tensorflow.keras.callbacks import EarlyStopping
from tensorflow.keras.optimizers import Adam

drive.mount('/content/drive')

file_path = '/content/drive/MyDrive/dlsp-portfolio-starter-code/cover_data.csv'

try:
    df = pd.read_csv(file_path)
    print(f"Successfully loaded file from: {file_path}")
except FileNotFoundError:
    print(f"Error: The file '{file_path}' was not found. Please ensure the path is correct and the file exists in your Google Drive.")
except Exception as e:
    print(f"An error occurred while reading the file: {e}")

features = df.iloc[:, 0:-1]
labels = df.iloc[:, len(df.columns) - 1:len(df.columns)]

X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42, stratify=labels)

#labels must be indexed at 0 for sparse categorical cross entropy
y_train = y_train - 1
y_test = y_test - 1

ct = ColumnTransformer([("scaler", StandardScaler(), X_train.columns)])
ct.fit_transform(X_train)
ct.transform(X_test)

model = Sequential()
input_shape = X_train.shape[1]
model.add(Dense(units=128, activation='relu', input_shape=(input_shape,)))
model.add(Dense(units=64, activation='relu'))
model.add(Dense(units=32, activation='relu'))
model.add(Dense(units=8, activation='relu'))
num_classes = y_train['class'].nunique()
model.add(Dense(units=num_classes, activation='softmax'))
model.summary()

optimizer = Adam(learning_rate=0.001)
model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])
print("Model compiled successfully with Adam optimizer, sparse_categorical_crossentropy loss, and accuracy metric.")

history = model.fit(X_train, y_train, epochs=100, batch_size=1024, validation_data=(X_test, y_test), callbacks=EarlyStopping(min_delta=0.001, patience=3, restore_best_weights=True))
print("Model training complete. Training history stored in 'history' variable.")